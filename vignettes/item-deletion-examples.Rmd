---
title: "Applied examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Applied examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning=FALSE, message=FALSE}
library(PartInvShinyUI)
library(lavaan)
```
\newcommand{\SR}{\text{SR}}
\newcommand{\CAI}{\text{CAI}}
\newcommand{\SE}{\text{SE}}
\newcommand{\SP}{\text{SP}}
\newcommand{\PS}{\text{PS}}
\newcommand{\TP}{\text{TP}}
\newcommand{\FN}{\text{FN}}
\newcommand{\FP}{\text{FP}}
\newcommand{\TN}{\text{TN}}
\newcommand{\str}{\text{str}}
\newcommand{\par}{\text{par}}
\newcommand{\td}{\tilde}
\newcommand{\rr}{\text{r-Ef}}
\newcommand{\ov}{\overline}

## Some notes on notation and examples of notation use

**Legend**

### Classification Accuracy Index (CAI)

- Proportion Selected: $\PS=\text{P(TP)}+\text{P(FP)}$

- Success Ratio: $\SP=\dfrac{\text{P(TP)}}{\text{P(TP)}+\text{P(FP)}}$

- Sensitivity: $\SE=\dfrac{\text{P(TP)}}{\text{P(TP)}+\text{P(FN)}}$

- Specificity: $\SP=\dfrac{\text{P(TN)}}{\text{P(TN)}+\text{P(FP)}}$

### 'Overall' Classification Accuracy Index $\left(\ov{\CAI}\right)$

- Overall PS: $\ov{\PS}  = \TP_{r}\times p_r + \TP_{f}\times (1-p_r) + \FP_{r}\times p_r + \FP_{f}\times (1-p_r)$

- Overall SR: $\ov{\SR} = \dfrac{\TP_{r}\times p_r + \TP_{f}\times (1-p_r)}{\TP_{r}\times p_r + \TP_{f}\times (1-p_r) + \FP_{r}\times p_r + \FP_{f}\times (1-p_r)}$
 
- Overall SE: $\ov{\SE} = \dfrac{\TP_{r}\times p_r + \TP_{f}\times (1-p_r)}{\TP_{r}\times p_r + \TP_{f}\times (1-p_r) + \FN_{r}\times p_r + \FN_{f}\times (1-p_r)}$

- Overall SP: $\ov{\SP} = \dfrac{\TN_{r}\times p_r + \TN_{f}\times (1-p_r)}{\TN_{r}\times p_r + \TN_{f}\times (1-p_r) + \FP_{r}\times p_r + \FP_{f}\times (1-p_r)}$

Unless otherwise indicated, we will 
assume that the full item set is used and that partial factorial invariance (PFI) 
holds.

If multiple operations are performed and multiple properties need to be indicated 
the outermost superscript indicates the current operation, and innermost 
superscript refers to constant properties. In other words, the superscript of
$h$ or $\Delta h$ indicates the current comparison (e.g., full vs. modified item set, 
strict vs. partial invariance, reference vs. focal groups). The superscript of an 
CAI refers to properties that are constant in in both groups being compared, 
and the subscript (if any) indicates that $h$ was computed on this CAI to compare
the conditions indicated in the subscript.

#### Indicating the set of items
- Let $I$ denote a set of items in a p-element scale, $I = \{i_1, i_2,\ldots,i_p\}$.
Then, we can denote the modified set of items after removing the k-th item as
$I^{|k}=\{i_1, i_2, ..., i_{k-1},i_{k+1}, ..., i_p\}$. Using this notation, we 
can refer to a Classification Accuracy Index (CAI)computed using the full set of items
as 'CAI' (e.g., SE), and the CAI computed using the modified set of items 
excluding item k as $\CAI^{|k}$ (e.g., $\SE^{|2}$ if the modified item set
excludes the second item).

#### Operations comparing the full vs. modified item sets
- $h(\CAI,\CAI^{|k})$ is denoted as $h^{|k}(\CAI)$, and the resulting 
h values are indicated as $\CAI_{|k}$.
- $\Delta h(\CAI,\CAI^{|k})$ is denoted as $\Delta h^{|k}(\CAI)$, and the 
resulting $\Delta h$ values as $\Delta h^{|k}\CAI$. 

- Note: $\Delta h$ is computed only for the comparison between the full and
modified item sets (not for group or invariance
condition comparisons).

- e.g., $\Delta h^{\text{|2}}(\CAI_{\rr})$ for quantifying the impact of dropping
the second item on the comparison between CAI for the r and Ef groups under 
PFI: $\Delta h^{|2}\CAI_{\rr}$.

- e.g., for the reference group, $h$ comparing CAI under SFI vs. PFI followed by
$\Delta h$ comparing these h values computed for the full item set and for the
modified item set excluding the 4th item: $\Delta h^{|4}\CAI^{r}_{\text{str, par}}$.

- e.g. $h^{|3}(\td{\CAI})$ for comparing the overall CAI under PFI: $\td{\CAI}_{|3}$.

#### h comparing the CAI of groups
- Reference group (r) can be compared with the focal group (f) or Efocal (Ef).

- $h^{\rr}(\CAI) = \CAI_{\rr}$ for h comparing the CAI of r and Ef groups under PFI,
for the full item set.
- $h^{\rr}(\CAI^{|2})=\CAI_{\rr}^{|2}$ for h comparing the CAI of r and Ef groups
for modified item set excluding the second item.
- $h^{\text{r-f}}(\CAI^{\str}) = \CAI_{\text{r-f}}^{\str}$ for h comparing the CAI 
of r and f groups under SFI, for the full item set.
- $h^{\text{r-f}}(\CAI^{|2;\str}) = \CAI_{\text{r-f}}^{|2; \str}$ for  h comparing
the CAI of r and f groups under SFI, for the modified item set excluding the
second item.

#### h comparing the CAI under SFI vs. PFI

- $h^{\text{str, par}}(\CAI^r)=\SE_{\text{str, par}}^r$ for h comparing the CAI 
under SFI vs. PFI (for the reference group).
- $h^{\text{str, par}}(\CAI^{|2; r})=\SE_{\text{str, par}}^{|2; r}$ for h 
comparing the CAI of r and Ef groups for modified item set excluding the second
item.

## Example from Lai, Kwok, Yoon and Hsiao (2017) 
Center for Epidemiological Studies Depression  (CES-D) Scale 

```{r}
# Zhang et al. (2011) BMC Medical Research Methodology, Tables 3-4 on page 7

# Reference group: Chinese, Focal group: Dutch
# 5:2 ratio, mixing proportion of 5/7

pmix_CESD_r <- 5/7

# Unstandardized factor loadings
lambda_SOM_r <- lambda_SOM_f <- c(1.00, 1.03, 1.18, 1.29, 1.07, 1.02, 1.26)
lambda_DEP_r <- lambda_DEP_f <- c(1.00, 1.13, 0.82, 0.91, 1.11, 0.92, 1.06)
lambda_POS_r <- lambda_POS_f <- c(1.00, 1.66, 2.30, 2.29)
lambda_INT_r <- lambda_INT_f <- c(1.00, 0.94)

# Unstandardized intercepts
nu_SOM_r <- c(0.69, 0.56, 0.78, 0.81, 0.88, 0.74, 0.70)
nu_SOM_f <- c(0.69, 0.56, 0.78, 0.80, 0.88, 0.74, 0.70)
nu_DEP_r <- c(0.52, 0.55, 0.57, 0.42, 0.57, 0.50, 0.56)
nu_DEP_f <- c(0.52, 0.55, 0.30, 0.42, 0.57, 0.50, 0.56)
nu_POS_r <- c(1.54, 1.36, 1.16, 1.08)
nu_POS_f <- c(0.68, 1.36, 1.16, 1.08)
nu_INT_r <- nu_INT_f <- c(0.44, 0.41)

# Unstandardized uniqueness
Theta_SOM_r <- Theta_SOM_f <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37))
Theta_DEP_r <- diag(c(0.29, 0.30, 0.41, 0.31, 0.29, 0.27, 0.24))
Theta_DEP_f <- diag(c(0.29, 0.13, 0.09, 0.14, 0.29, 0.27, 0.24))
Theta_POS_r <- diag(c(1.20, 0.81, 0.32, 0.32))
Theta_POS_f <- diag(c(0.72, 0.81, 0.32, 0.32))
Theta_INT_r <- diag(c(0.19, 0.23))
Theta_INT_f <- diag(c(0.19, 0.08))

# Latent mean differences
alpha_SOM_r <- 0
alpha_DEP_r <- 0
alpha_POS_r <- 0
alpha_INT_r <- 0
alpha_SOM_f <- -0.261
alpha_DEP_f <- -0.259
alpha_POS_f <- -0.125
alpha_INT_f <- -0.323

# Latent mean variances
psi_SOM_r <- 0.482^2
psi_SOM_f <- 0.324^2
psi_DEP_r <- 0.570^2
psi_DEP_f <- 0.318^2
psi_POS_r <- 0.354^2
psi_POS_f <- 0.329^2
psi_INT_r <- 0.574^2
psi_INT_f <- 0.184^2
```
 
 
```{r ex1, include=FALSE}
# ex1 <- item_deletion_h(weights_item = c(1, 1, 1, 1), 
#                               propsel = .14, n_dim = 1,  
#                               alpha_r = 0,
#                               alpha_f =-0.125,
#                               psi_r = 0.354^2,
#                               psi_f = 0.329^2,
#                               lambda_r = c(1.00, 1.66, 2.30, 2.29),
#                               lambda_f = c(1.00, 1.66, 2.30, 2.29),
#                               nu_r = c(1.54, 1.36, 1.16, 1.08),
#                               nu_f = c(0.68, 1.36, 1.16, 1.08),
#                               Theta_r = diag(c(1.20, 0.81, 0.32, 0.32)), 
#                               Theta_f = diag(c(0.72, 0.81, 0.32, 0.32)),
#                               weights_latent = 1,
#                               plot_contour = FALSE,
#                               return_detailed = TRUE,
#                               pmix_ref = 5/7)
```
 
```{r CESD_full, include=FALSE}
# lambda_CESD_r <- rbind(cbind(lambda_SOM_r, rep(0, 7), rep(0, 7), rep(0, 7)),
#                        cbind(rep(0, 7), lambda_DEP_r, rep(0, 7), rep(0, 7)),
#                        cbind(rep(0, 4), rep(0, 4), lambda_POS_r, rep(0, 4)),
#                        cbind(rep(0, 2), rep(0, 2), rep(0, 2), lambda_INT_r))
# lambda_CESD_f <- rbind(cbind(lambda_SOM_f, rep(0, 7), rep(0, 7), rep(0, 7)),
#                        cbind(rep(0, 7), lambda_DEP_f, rep(0, 7), rep(0, 7)),
#                        cbind(rep(0, 4), rep(0, 4), lambda_POS_f, rep(0, 4)),
#                        cbind(rep(0, 2), rep(0, 2), rep(0, 2), lambda_INT_f))
# psi_CESD_r <- as.matrix(c(psi_SOM_r, psi_DEP_r, psi_POS_r, psi_INT_r))
# psi_CESD_f <- as.matrix(c(psi_SOM_f, psi_DEP_f, psi_POS_f, psi_INT_f))
# alpha_CESD_r <- as.matrix(c(alpha_SOM_r, alpha_DEP_r, alpha_POS_r, alpha_INT_r))
# alpha_CESD_f <- as.matrix(c(alpha_SOM_f, alpha_DEP_f, alpha_POS_f, alpha_INT_f))

# Theta_CESD_r <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37, #SOM
#                   0.29, 0.30, 0.41, 0.31, 0.29, 0.27, 0.24, #DEP
#                   1.20, 0.81, 0.32, 0.32, #POS
#                   0.19, 0.23 #INT
#                   ))
# Theta_CESD_f <- diag(c(0.45, 0.37, 0.39, 0.40, 0.57, 0.51, 0.37, #SOM
#                   0.29, 0.13, 0.09, 0.14, 0.29, 0.27, 0.24, #DEP
#                   0.72, 0.81, 0.32, 0.32, #POS
#                   0.23, 0.08 #INT
#                   ))
# nu_CESD_r <- as.matrix(c(nu_SOM_r, nu_DEP_r, nu_POS_r, nu_INT_r))
# nu_CESD_f <- as.matrix(c(nu_SOM_f, nu_DEP_f, nu_POS_f, nu_INT_f))

# CESD_full <- item_deletion_h(weights_item = c(rep(1, 20)), 
#                             propsel = .14, n_dim = 1,  
#                             alpha_r = alpha_CESD_r,
#                             alpha_f = alpha_CESD_f,
#                             psi_r = psi_CESD_r,
#                             psi_f = psi_CESD_f,
#                             lambda_r = lambda_CESD_r,
#                             lambda_f = lambda_CESD_f,
#                             nu_r = nu_CESD_r,
#                             nu_f = nu_CESD_f,
#                             Theta_r = Theta_CESD_r, 
#                             Theta_f = Theta_CESD_f,
#                             weights_latent = 1,
#                             plot_contour = FALSE,
#                             return_detailed = FALSE,
#                             pmix_ref = pmix_CESD_r)
# CESD_full
```
 
 
```{r}
#Positive Affect Factor
#Items: good (biased), hopeful, happy, enjoyed

CESD_pos <- item_deletion_h(weights_item = c(rep(1,4)), 
                              propsel = .14, n_dim = 1,  
                              alpha_r = alpha_POS_r,
                              alpha_f = alpha_POS_f,
                              psi_r = psi_POS_r,
                              psi_f = psi_POS_f,
                              lambda_r = lambda_POS_r,
                              lambda_f = lambda_POS_f,
                              nu_r = nu_POS_r,
                              nu_f = nu_POS_f,
                              Theta_r = Theta_POS_r, 
                              Theta_f = Theta_POS_f,
                              weights_latent = 1,
                              plot_contour = FALSE,
                              return_detailed = FALSE,
                              pmix_ref = pmix_CESD_r, 
                            biased_items_only=TRUE
                           # user_specified_items = c(1,2)
                           )
CESD_pos 

# Depressive Affect Factor 
# Items: blues, depressed, lonely, crying, sad, failure, fearful
CESD_dep <- item_deletion_h(weights_item = c(rep(1,7)), 
                              propsel = .14, n_dim = 1,  
                              alpha_r = alpha_DEP_r,
                              alpha_f = alpha_DEP_f,
                              psi_r = psi_DEP_r,
                              psi_f = psi_DEP_f,
                              lambda_r = lambda_DEP_r,
                              lambda_f = lambda_DEP_f,
                              nu_r = nu_DEP_r,
                              nu_f = nu_DEP_f,
                              Theta_r = Theta_DEP_r, 
                              Theta_f = Theta_DEP_f,
                              weights_latent = 1,
                              plot_contour = FALSE,
                              return_detailed = FALSE,
                              pmix_ref = pmix_CESD_r, 
                            biased_items_only = TRUE)
CESD_dep # items 2, 3, 4 are biased

# Somatic Complaints 
# Items: bothered, appetite, mind, effort, sleep, talk, get going
CESD_som <- item_deletion_h(weights_item = c(rep(1,7)), 
                              propsel = .14, n_dim = 1,  
                              alpha_r = alpha_SOM_r,
                              alpha_f = alpha_SOM_f,
                              psi_r = psi_SOM_r,
                              psi_f = psi_SOM_f,
                              lambda_r = lambda_SOM_r,
                              lambda_f = lambda_SOM_f,
                              nu_r = nu_SOM_r,
                              nu_f = nu_SOM_f,
                              Theta_r = Theta_SOM_r, 
                              Theta_f = Theta_SOM_f,
                              weights_latent = 1,
                              plot_contour = FALSE,
                              return_detailed = TRUE,
                              pmix_ref = pmix_CESD_r)
CESD_som #  item 4 is biased (?)

# Interpersonal Problems
# Items: unfriendly, dislike
CESD_int <- item_deletion_h(weights_item = c(rep(1,2)), 
                              propsel = .14, n_dim = 1,  
                              alpha_r = alpha_INT_r,
                              alpha_f = alpha_INT_f,
                              psi_r = psi_INT_r,
                              psi_f = psi_INT_f,
                              lambda_r = lambda_INT_r,
                              lambda_f = lambda_INT_f,
                              nu_r = nu_INT_r,
                              nu_f = nu_INT_f,
                              Theta_r = Theta_INT_r, 
                              Theta_f = Theta_INT_f,
                              weights_latent = 1,
                              plot_contour = FALSE,
                              return_detailed = TRUE,
                              pmix_ref = pmix_CESD_r)
CESD_int #item 2 is biased
```

###### `h_overall_par`
$h^{|k}(\td{\CAI})$: Cohen's h effect size for the improvement/drop in overall
CAI under PFI when the k-th item is removed. 'Overall' 
refers to the averaging of accuracy indices across focal and reference groups
by group proportions to arrive at a weighted average for each CAI (regularly
computed as $\SR=\frac{\TP}{\TP+\FP}$, $\SE=\frac{\TP}{\TP+\FN}$, 
$\SR=\frac{\TN}{\TN+\FP}$). 
Letting $p_r$ denote the weight for the reference group,

$$\td{\SR} = \frac{\TP_{r}\times p_r + \TP_{f}\times (1-p_r)}{\TP_{r}\times p_r + \TP_{f}\times (1-p_r) + \FP_{r}\times p_r + \FP_{f}\times (1-p_r)}$$
$$\td{\SE} = \frac{\TP_{r}\times p_r + \TP_{f}\times (1-p_r)}{\TP_{r}\times p_r + \TP_{f}\times (1-p_r) + \FN_{r}\times p_r + \FN_{f}\times (1-p_r)}$$
$$\td{\SP} = \frac{\TN_{r}\times p_r + \TN_{f}\times (1-p_r)}{\TN_{r}\times p_r + \TN_{f}\times (1-p_r) + \FP_{r}\times p_r + \FP_{f}\times (1-p_r)}$$

Then, the change in overall CAI after dropping the k-th item can be computed as
$$h^{|k}\td{\CAI} = 2\arcsin\left(\sqrt{\td{\CAI}}\right)-2\arcsin\left(\sqrt{\td{\CAI}^{|k}}\right)$$

A negative `h_overall_CAI_par` indicates an improvement 
(as $h^{|k}\td{\CAI}<0 \iff \td{\CAI}<\td{\CAI}^{|k}$)
whereas a positive
`h_overall_CAI_par` indicates a deterioration in performance.


For the 4-item CES-D scale, the negative $h^{|1}(\td{\SR})$,
$h^{|1}(\td{\SE})$, and $h^{|1}(\td{\SP})$ values 
indicate that removing the first item would lead to an improvement in SR, 
SE, and SP. On the other hand, the positive $h$ values for modified item sets 
excluding items 2, 3, or 4 suggest that SR, SE, and SP decreases if any of these 
items are dropped.

##### `delta_h`

$\Delta h$ is computed using the following formula to compare the effect size of 
the change in an CAI when the k=th item is dropped:
$$\Delta h^{|k}(\CAI)=\text{sign}\left(| h^{(.)}({\CAI)}|-|h^{(.)}(\CAI^{|k})|\right)\left||h^{(.)}(\CAI^{|k})|-|h^{(.)}(\CAI)|\right|$$
'(.)' in the superscript of h is a placeholder for the comparison performed in 
the previous step.

`delta_h` contains two elements: `delta_h$h_R_vs_Ef.par` and 
`delta_h$h_str_vs_par`, with the latter containing two tables (one for reference
and the second for focal group comparisons).

#### `delta_h$h_R_vs_Ef.par`
$\Delta h^{|k}({\CAI_{\rr}})$: Effect size of the change in $\CAI_{\rr}$ 
(stored in `h$R_vs_Ef.par`) when the k-th item is dropped, under PFI. $\CAI_{\rr}$ refers to the Cohen's effect size 
for the comparison in CAI for the reference group vs. the focal group if it 
followed the same distribution as the reference group. 

HL: # (I would suggest separating out PS from SR, SE, and SP here, as PS is more a fairness index whereas SR, SE, SP are more about accuracy. We may only need delta h for PS. )

$$\Delta h^{|k}(\CAI_{\rr})=\text{sign}\left(| h^{\rr}({\CAI)}|-|h^{\rr}(\CAI^{|k})|\right)\left||h^{\rr}(\CAI^{|k})|-|h^{\rr}(\CAI)|\right|$$
Equivalently, substituting $\CAI_{\rr}$ for $h^{\rr}({\CAI)}$, 

$$\Delta h^{|k}(\CAI_{\rr})=\text{sign}\left(| \CAI_{\rr}|-|\CAI^{|k}_{\rr}|\right)\left||\CAI^{|k}_{\rr}|-|\CAI_{\rr}|\right|$$

Looking at PS, Delta h is only positive for the comparison between the full item
set and the set where item 1 is deleted. As we know that item 1 is biased, this 
indicates that seeing a positive delta h in PS is an indication that that item
should be removed. We see the opposite patterns for item 1 vs. items 2-4 where 
removing any of item 2, 3, or 4 would harm the accuracy indices.

#### `delta_h$h_str_vs_par`: `ref` and `foc`

- $\Delta h^{|k}(\CAI^{r}_{\str,\par})$, stored in `delta_h$h_str_vs_par.ref`, 
refers to the effect size of the change in $\CAI^{r}_{\str,\par}$
when the k-th item is dropped. $\CAI^{r}_{\str,\par}$ (stored in 
`h$str_vs_par$ref`) refers to the Cohen's effect size
for the comparison in CAI under SFI vs. 
PFI, for a given set of items for the reference group.

\[
\begin{align*}
\Delta h^{|k}(\CAI^{r}_{\str,\par})&= \text{sign}\left(|\CAI^{r}_{\str,\par}| - |\CAI^{|k,r}_{\str,\par}| \right)\left||\CAI^{|k,r}_{\str,\par} |-|\CAI^{r}_{\str,\par}|\right|
\end{align*}
\]

- $\Delta h^{|k}(\CAI^{f}_{\str,\par})$, stored in `delta_h$h_str_vs_par.foc`, 
refers to the effect size of the change in $\CAI^{f}_{\str,\par}$
when the k-th item is dropped. $\CAI^{f}_{\str,\par}$ (stored in 
`h$str_vs_par$foc`) refers to the Cohen's effect size
for the comparison in CAI under SFI vs. 
PFI, for a given set of items for the focal group.
\[
\begin{align*}
\Delta h^{|k}(\CAI^{f}_{\str,\par})&= \text{sign}\left(|\CAI^{f}_{\str,\par}| - |\CAI^{|k,f}_{\str,\par}| \right)\left||\CAI^{|k,f}_{\str,\par} |-|\CAI^{f}_{\str,\par}|\right|\\
\end{align*}
\]

#### `h$R_vs_Ef.par`
[HL]: # (We can call the following 'bias'. It'd be helpful to discuss the 'full' column first.)

$h^{\text{r- Ef}}(\CAI)$: is the effect size of the comparison between CAI 
of the reference group vs. the expected CAI for the focal group if it 
followed the same distribution as the reference group under PFI. Note that
$h^{\text{r- Ef}}(\CAI)=0$ under SFI.

\[
\begin{align*}
h^{\rr}(\CAI) &= 2\text{arcsin}\left(\sqrt{\CAI^r}\right)-2\text{arcsin}\left(\sqrt{\CAI^{Ef}}\right)=\CAI_{\rr}\\
h^{\rr}(\CAI^{|k}) &= 2\text{arcsin}\left(\sqrt{\CAI^{|k,r}}\right)-2\text{arcsin}\left(\sqrt{\CAI^{|k,Ef}}\right)=\CAI^{|k}_{\rr}
\end{align*}
\]


$\PS^{|1}_{\rr}=0$,$\SR^{|1}_{\rr}=0$,
$\SE^{|1}_{\rr=0}$, $\SP^{|1}_{\rr}=0$ suggest that 
if we delete the first item, the accuracy indices for the Efocal group under
PFI will be equal to that of the reference group under PFI, *thus removing bias*. 

$\PS_{\rr}=0.203$ indicates the proportion selected in the reference group is
larger than the proportion selected in Efocal. In other words, *the reference group is favored when the full set of items are used*. Under the expected distribution for the 
reference group, the focal group would have a higher success ratio and a higher
specificity than the reference group when for item sets $\{I, I^{|2}, I^{|3}, I^{|4}\}$ but would have a lower proportion selected and a lower sensitivity.
Dropping any item other than the first item would lead to a similar situation where
a greater proportion is selected from the reference group than the focal group
and is not advisable despite leading to an increase in SE.



#### `h$str_vs_par`: `ref` and `foc`
`h$str_vs_par$ref` and `h$str_vs_par$foc` compare CAI under SFI vs. PFI for a given
set of items
for the reference and focal groups respectively.

`h$str_vs_par$ref`:
\[
\begin{align*}
h^{\str,\par}(\CAI^{r}) &= 2\text{arcsin}\left(\sqrt{\CAI^{r, \str}}\right)-2\text{arcsin}\left(\sqrt{\CAI^{r,\par}}\right)\\
h^{\str,\par}(\CAI^{|k,r}) &= 2\text{arcsin}\left(\sqrt{\CAI^{|k,r,\str}}\right)-2\text{arcsin}\left(\sqrt{\CAI^{|k,r,\par}}\right)
\end{align*}
\]

`h$str_vs_par$foc`:

\[
\begin{align*}
h^{\str,\par}(\CAI^{f}) &= 2\text{arcsin}\left(\sqrt{\CAI^{f, \str}}\right)-2\text{arcsin}\left(\sqrt{\CAI^{f,\par}}\right)\\
h^{\str,\par}(\CAI^{|k,f}) &= 2\text{arcsin}\left(\sqrt{\CAI^{|k,f,\str}}\right)-2\text{arcsin}\left(\sqrt{\CAI^{|k,f,\par}}\right)
\end{align*}
\]

$\PS^{r}_{\str,\par}=-0.040$ indicates that 
PS was slightly higher under PFI compared to under SFI for the full item set and when any of items 2-4 was deleted. Deleting
item 1 brought the effect size of the difference between SFI and PFI conditions to 0 for all accuracy indices.




## Example from Millsap, Kwok (2004)
'Evaluating the Impact of Partial Factorial Invariance on
Selection in Two Populations'

Biased items: 3, 4
```{r}
# Worry subscale of the test anxiety inventory
ex2 <- item_deletion_h(weights_item = c(1, 1, 1, 1, 1, 1, 1, 1), 
                              propsel = 0.1000001,#"90% cutpoint"
                              #cut_z= 23.29952,
                             n_dim = 1,  
                             alpha_r = 0,
                             alpha_f =-0.126,
                             psi_r = 0.544,
                             psi_f = 0.477,
                             lambda_r = c(0.836, 1, 0.904, 0.808, 0.903,
                                             0.960, 0.934, 0.934),
                             lambda_f = c(0.836, 1, 1.111, 1.001, 0.903, 
                                             0.960, 0.934, 0.934),
                             nu_r = c(2.114, 2.064, 1.901, 2.004, 2.144,
                                        1.985, 2.179, 2.230),
                             nu_f= c(2.114, 2.064, 1.880, 1.985, 2.144,
                                        1.985, 2.179, 2.230),
                             Theta_r = diag(c(.517, .523, .631, .585, .481,
                                                .469,.551,.572)),
                             Theta_f = diag(c(.514, .407, .371, .475, .392,
                                                .335,.454,.457)),
                             weights_latent = 1,
                             plot_contour = FALSE,
                             return_detailed = FALSE, pmix_ref = 0.5)
```



```{r}
ex2
```

The positive h values in h_overall_CAI_par suggest that no item should be 
dropped, as dropping any of the items would lead to a lower success ratio, lower
sensitivity, and lower specificity.

`h$R_vs_Ef.par`

If the focal group followed the same distribution as the reference group, a larger
proportion would be selected for the focal group compared to the reference group 
(indicated by the negative PS) when all items are used. If any one item is dropped
there would be an increase in PS for the reference group, leading to a positive h.




A greater proportion is selected under SFI compared to PFI when all items are used, but when any of the 8 items are dropped, a 
greater proportion is selected under PFI. SR, SE, SP are always
positive, indicating that regardless of item drop condition, 
SR, SE, SP under SFI is always larger than SR, SE, SP under PFI. 



## Example from Ock, McAbee, Mulfinger, and Oswald (2020)
'The Practical Effects of Measurement Invariance: Gender Invariance in Two Big Five Personality Measures'
Biased items: 1, 7, 11, 13, 14
```{r read data, include  = FALSE}
data <- read.table("IPIPFFM.dat", header = TRUE)
head(data)
male <- data[data$sex == 1, ]
female <- data[data$sex == 2, ]
```

```{r specify and fit model}
model <- 'A =~  a2 + a5  + a7 + a9
          C =~  c3 + c4 + c8 + c9
          E =~ e1 + e4 + e6 + e7
          N =~ n1 + n2 + n6 + n8
          O =~ i2 + i8 + i9 + i10
          a2 ~~ a5
          e4 ~~ e7  
          i2 ~~ i10
          i8 ~~ i9
          a9 ~~ i9
          c3 ~~ e6
          a2 ~~ e7
          e7 ~~ n2'
fit_strict <- cfa(model, data = data, group = "sex",
                  group.equal = c("loadings", "Intercepts", "residuals"),
                  group.partial = c("e6 ~ 1", "n1 ~ 1", "n2 ~ 1", "a2 ~ 1", 
                                    #items  1 (A2), 7 (C8), 11 (E6), 13 (N1), 14 (N2)
                                    "n2 ~~ n2", "n1 ~~ n1", "c8 ~~ c8"),
                  estimator = "MLR", std.lv = TRUE)
result <- lavInspect(fit_strict, what = "est")
```

```{r IPIPFFM item deletion}
ex3 <- item_deletion_h(propsel=0.25,
              weights_item = c(3.1385, 3.1385, 3.1385, 3.1385,
                                8.3203, 8.3203, 8.3203, 8.3203,
                                5.1586, 5.1586, 5.1586, 5.1586,
                                -6.5870, -6.5870, -6.5870, -6.5870,
                                1.7957, 1.7957, 1.7957, 1.7957), 
              n_dim = 5, 
              alpha_r = result[[2]]$alpha,
              alpha_f = result[[1]]$alpha,
              psi_r = result[[2]]$psi,
              psi_f = result[[1]]$psi,
              lambda_r = result[[2]]$lambda,
              lambda_f = result[[1]]$lambda,
              nu_r = result[[2]]$nu,
              nu_f = result[[1]]$nu,
              Theta_r = result[[2]]$theta,
              Theta_f = result[[1]]$theta,
              weights_latent = c(0.12553907, 0.33281060, 0.20634298, 
                                 -0.26347936, 0.07182799),
              plot_contour = FALSE, 
              return_detailed = FALSE,
              user_specified_items = c(1,7,11,13,14))
```

```{r}
ex3
```

Looking at `h_overall_par`, we see that dropping item 1 would lead to
a marginal improvement in SR and SP, while SE would be unaffected. We see a similar
pattern with item 18. 

Item 12 appears to be a bad item to drop as dropping this item produces the highest
h values (i.e., the largest decrease in SR, SE, and SP) in this example, followed
by items 10 and 11. Conversely, removing item 4 would not harm SR, SP, or SE.

Out of the biased items (1, 7, 11, 13, and 14), we should consider dropping item 1
and retaining item 11.

When item 11 is dropped, h for PS is negative (a higher proportion is selected 
under Efocal than the reference group). For all other item drop conditions, h for 
PS is positive. 